# Site
repository: sproogen/resume-theme
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Hyundong Jin 
title: Curriculum Vitae
email: jude0316@cau.ac.kr
website: https://github.com/Jin0316

# Dark Mode (true/false/never)
darkmode: true

# Social links
# twitter_username: facespics
github_username:  Jin0316
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
# instagram_username: jameswgrant
# linkedin_username: jameswgrant
# xing_username: jekyll
# pinterest_username: jekyll
# youtube_username: globalmtb
# googleplus_username: +jekyll
# orcid_username: 0000-0000-0000-0000

# Additional icon links
# additional_links:
# - title: itsgoingto.be
#   icon: fas fa-globe
#   url: https://www.itsgoingto.be
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me
about_profile_image: images/profile_hyundongjin.png

about_content: | # this will include new lines to allow paragraphs
  Hi, my name's Hyundong and I'm a Ph.D candidate in ChunAng-University, Seoul, South Korea. 
  My research interests include deep learning, machine learning, continual learning, and computer vision

  I am most skilled in: Continual Learning

content:

  - title: Education  # Title for the section
    layout: list # Type of content section (list/text)
    
    content:
      - layout: left
        title: Chung-Ang University
        caption: Mar. 2022 - present
        description: | # this will include new lines to allow paragraphs
            Ph.D. of Computer Science Engineering (advisor: Eunwoo Kim)
    content:
      - layout: left
        title: Chung-Ang University
        caption: Mar. 2020 - Feb.2022
        description: | # this will include new lines to allow paragraphs
            Master of Computer Science Engineering (advisor: Eunwoo Kim)
            
    content:
      - layout: left
        title: Chung-Ang University
        caption: Mar. 2015 - Feb.2020
        description: | # this will include new lines to allow paragraphs
            Bachelor of Electrical and Electronics Engineering.
            
  - title: Papers # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: top-middle
        title: Helpful or Harmful: Inter-Task Association in Continual Learning, HyundongJin and Eunwoo Kim, ECCV, 2022. 
        link: https://github.com/Jin0316/Helpful-or-Harmful-Inter-Task-Association
        # link_text: Project Website
        description: | # this will include new lines to allow paragraphs
          Abstract: When optimizing sequentially incoming tasks, deep neural networks generally suffer from catastrophic forgetting due to their lack of ability to maintain knowledge from old tasks. 
                    This may lead to a significant performance drop of the previously learned tasks. To alleviate this problem, studies on continual learning have been conducted as a countermeasure. 
                    Nevertheless, it suffers from an increase in computational cost due to the expansion of the network size or a change in knowledge that is favorably linked to previous tasks. 
                    In this work, we propose a novel approach to differentiate helpful and harmful information for old tasks using a model search to learn a current task effectively. 
                    Given a new task, the proposed method discovers an underlying association knowledge from old tasks, which can provide additional support in acquiring the new task knowledge. 
                    In addition, by introducing a sensitivity measure to the loss of the current task from the associated tasks, we find cooperative relations between tasks while alleviating harmful interference. 
                    We apply the proposed approach to both task- and class-incremental scenarios in continual learning, using a wide range of datasets from small to large scales.
                    Experimental results show that the proposed method outperforms a large variety of continual learning approaches for the experiments while effectively alleviating catastrophic forgetting.
    content:
      - layout: top-middle
        title: Gating Mechanism in Deep Neural Networks for Resource-Efficient Continual Learning, HyundongJin, Kimin Yoon, and Eunwoo Kim, IEEE Access, 2022. 
        link: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9695483
        description: |
          Abstract: Catastrophic forgetting is a well-known tendency in continual learning of a deep neural network to forget previously learned knowledge when optimizing for sequentially incoming tasks. 
                    To address the issue, several methods have been proposed in research on continual learning. 
                    However, these methods cannot preserve the previously learned knowledge when training for a new task. 
                    Moreover, these methods are susceptible to negative interference between tasks, which may lead to catastrophic forgetting. 
                    It even becomes increasingly severe when there exists a notable gap between the domains of tasks. 
                    This paper proposes a novel method of controlling gates to select a subset of parameters learned for old tasks, which are then used to optimize a new task while avoiding negative interference efficiently. 
                    The proposed approach executes the subset of old parameters that provides positive responses by evaluating the effect when the old and new parameters are used together. 
                    The execution or skipping of old parameters through the gates is based on several responses across the network. 
                    We evaluate the proposed method in different continual learning scenarios involving image classification datasets. 
                    The proposed method outperforms other competitive methods and requires fewer parameters than the state-of-the-art methods during inference by applying the proposed gating mechanism that selectively involves a set of old parameters that provides positive prior knowledge to newer tasks. 
                    Additionally, we further prove the effectiveness of the proposed method through various analyses.

        
  - title: Education  # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: The Boring Company
        link: boringcompany.com
        # link_text: boringcompany.com
        sub_title: Senior Network System Administrator
        caption: November 2017 - Present
        quote: >
          Solving 21st century problems by diging holes and making game changing products like the *not a flamethrower*
        description: | # this will include new lines to allow paragraphs
            Every company needs its networks properly administered and The Boring Compay is no exception. Digging holes is hard and I play my part making sure the whole company stays connected. I lead a team of 5 people and enjoy driving the company to try new technologies.

  - title: Invited Talk # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Feb. 2023
        description: | # this will include new lines to allow paragraphs
          2023 Korean Computer Vision Society (KCVS), Continual Learning session.
    content:
      - layout: left
        title: Dec. 2023
        description: | # this will include new lines to allow paragraphs
          2022 Korean Artificial Intelligence Association (KAIA) and NAVER, CV / NLP session. 
# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
